<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="What do I get from WebRTC&rsquo;s media communication? #  WebRTC allows you to send and receive an unlimited amount of audio and video streams. You can add and remove these streams at anytime during a call. These streams could all be independent, or they could be bundled together! You could send a video feed of your desktop, and then include audio/video from your webcam.
The WebRTC protocol is codec agnostic."><meta name=theme-color content="#FFFFFF"><meta property="og:title" content="Media Communication"><meta property="og:description" content="What do I get from WebRTC&rsquo;s media communication? #  WebRTC allows you to send and receive an unlimited amount of audio and video streams. You can add and remove these streams at anytime during a call. These streams could all be independent, or they could be bundled together! You could send a video feed of your desktop, and then include audio/video from your webcam.
The WebRTC protocol is codec agnostic."><meta property="og:type" content="article"><meta property="og:url" content="https://webrtcforthecurious.com/docs/06-media-communication/"><meta property="article:modified_time" content="2021-02-27T13:54:30-08:00"><meta property="og:site_name" content="WebRTC for the Curious"><title>Media Communication | WebRTC for the Curious</title><link rel=manifest href=/manifest.json><link rel=icon href=/favicon.png type=image/x-icon><link rel=alternate hreflang=tr href=https://webrtcforthecurious.com/tr/docs/06-media-communication/ title="Media Communication"><link rel=alternate hreflang=zh href=https://webrtcforthecurious.com/zh/docs/06-media-communication/ title=媒体通信><link rel=stylesheet href=/book.min.6cd8553a6854f4812343f0f0c8baca31271e686434f381fbe3c7226f66639176.css integrity="sha256-bNhVOmhU9IEjQ/DwyLrKMSceaGQ084H748cib2ZjkXY="><script defer src=/en.search.min.3d7a423ed0c7ed78e00e33de9a87472d8faeba28d8005d84028d0a42c180b1cd.js integrity="sha256-PXpCPtDH7XjgDjPemodHLY+uuijYAF2EAo0KQsGAsc0="></script></head><body><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><nav><h2 class=book-brand><a href=/><span>WebRTC for the Curious</span></a></h2><div class=book-search><input type=text id=book-search-input placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><ul><li><a href=/docs/01-what-why-and-how/>What, Why and How</a></li><li><a href=/docs/02-signaling/>Signaling</a></li><li><a href=/docs/03-connecting/>Connecting</a></li><li><a href=/docs/04-securing/>Securing</a></li><li><a href=/docs/05-real-time-networking/>Real-time Networking</a></li><li><a href=/docs/06-media-communication/ class=active>Media Communication</a></li><li><a href=/docs/07-data-communication/>Data Communication</a></li><li><a href=/docs/08-applied-webrtc/>Applied WebRTC</a></li><li><a href=/docs/09-debugging/>Debugging</a></li><li><a href=/docs/10-history-of-webrtc/>History</a></li><li><a href=/docs/11-faq/>FAQ</a></li></ul></nav><script>(function(){var menu=document.querySelector("aside.book-menu nav");addEventListener("beforeunload",function(event){localStorage.setItem("menu.scrollTop",menu.scrollTop);});menu.scrollTop=localStorage.getItem("menu.scrollTop");})();</script></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/svg/menu.svg class=book-icon alt=Menu></label>
<strong>Media Communication</strong>
<label for=toc-control><img src=/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><a href=#how-does-it-work>How does it work?</a></li><li><a href=#latency-vs-quality>Latency vs Quality</a><ul><li><a href=#real-world-limitations>Real World Limitations</a></li></ul></li><li><a href=#media-101>Media 101</a><ul><li><a href=#codec>Codec</a></li><li><a href=#frame-types>Frame Types</a></li></ul></li><li><a href=#rtp>RTP</a><ul><li><a href=#packet-format>Packet Format</a></li><li><a href=#extensions>Extensions</a></li><li><a href=#mapping-payload-types-to-codecs>Mapping Payload Types to Codecs</a></li></ul></li><li><a href=#rtcp>RTCP</a><ul><li><a href=#packet-format-1>Packet Format</a></li><li><a href=#full-intra-frame-request>Full INTRA-frame Request</a></li><li><a href=#negative-acknowledgements>Negative ACKnowledgements</a></li><li><a href=#senderreceiver-reports>Sender/Receiver Reports</a></li><li><a href=#generic-rtp-feedback>Generic RTP Feedback</a></li></ul></li><li><a href=#how-rtprtcp-solve-problems>How RTP/RTCP solve problems</a><ul><li><a href=#negative-acknowledgment>Negative Acknowledgment</a></li><li><a href=#forward-error-correction>Forward Error Correction</a></li><li><a href=#adaptive-bitrate-and-bandwidth-estimation>Adaptive bitrate and Bandwidth Estimation</a></li><li><a href=#congestion-control>Congestion Control</a></li><li><a href=#jitterbuffer>JitterBuffer</a></li></ul></li></ul></nav></aside></header><article class=markdown><h1 id=what-do-i-get-from-webrtcs-media-communication>What do I get from WebRTC&rsquo;s media communication?
<a class=anchor href=#what-do-i-get-from-webrtcs-media-communication>#</a></h1><p>WebRTC allows you to send and receive an unlimited amount of audio and video streams. You can add and remove these streams at anytime during a call. These streams could all be independent, or they could be bundled together! You could send a video feed of your desktop, and then include audio/video from your webcam.</p><p>The WebRTC protocol is codec agnostic. The underlying transport supports everything, even things that don&rsquo;t exist yet! However, the WebRTC Agent you are communicating with may not have the necessary tools to accept it.</p><p>WebRTC is also designed to handle dynamic network conditions. During a call your bandwidth might increase, or decrease. Maybe you all the sudden experience lots of packet loss. The protocol is designed to handle all of this. WebRTC responds to network conditions and tries to give you the best experience possible with the resources available.</p><h2 id=how-does-it-work>How does it work?
<a class=anchor href=#how-does-it-work>#</a></h2><p>WebRTC uses two pre-existing protocols RTP and RTCP, both defined in <a href=https://tools.ietf.org/html/rfc1889>RFC 1889</a></p><p>RTP (Real-time Transport Protocol) is the protocol that carries the media. It was designed to allow for real-time delivery of video. It does not stipulate any rules around latency or reliability, but gives you the tools to implement them. RTP gives you streams, so you can run multiple media feeds over one connection. It also gives you the timing and ordering information you need to feed a media pipeline.</p><p>RTCP (RTP Control Protocol) is the protocol that communicates metadata about the call. The format is very flexible and allows you to add any metadata you want. This is used to communicate statistics about the call. It is also used to handle packet loss and to implement congestion control. It gives you the bi-directional communication necessary to respond to changing network conditions.</p><h2 id=latency-vs-quality>Latency vs Quality
<a class=anchor href=#latency-vs-quality>#</a></h2><p>Real-time media is about making trade-offs between latency and quality. The more latency you are willing to tolerate, the higher quality video you can expect.</p><h3 id=real-world-limitations>Real World Limitations
<a class=anchor href=#real-world-limitations>#</a></h3><p>These constraints are all caused by the limitations of the real world. They are all characteristics of your network that you will need to overcome.</p><h4 id=bandwidth>Bandwidth
<a class=anchor href=#bandwidth>#</a></h4><p>Bandwidth is the maximum rate of data that can be transferred across a given path. It is important to remember this isn&rsquo;t a static number either. The bandwidth will change along the route as more (or less) people use it.</p><p>When you attempt to send more data then available bandwidth you will experience network congestion.</p><h4 id=transmission-time>Transmission Time
<a class=anchor href=#transmission-time>#</a></h4><p>Transmission Time is how long it takes for a packet to arrive. Like Bandwidth this isn&rsquo;t constant. The Transmission Time can fluctuate at anytime.</p><h4 id=jitter>Jitter
<a class=anchor href=#jitter>#</a></h4><p>Jitter is the fact that <code>Transmission Time</code> may vary. Some times you will see packets arrive in bursts. Any piece of hardware along the network path can introduce issues.</p><h4 id=packet-loss>Packet Loss
<a class=anchor href=#packet-loss>#</a></h4><p>Packet Loss is when messages are lost in transmission. The loss could be steady, or it could come in spikes. This is also a common issue, especially on wireless networks!</p><h4 id=maximum-transmission-unit>Maximum transmission unit
<a class=anchor href=#maximum-transmission-unit>#</a></h4><p>Maximum Transmission Unit is the limit on how large a single packet can be. Networks don&rsquo;t allow you to send one giant message. At the protocol level, you need to split your data into multiple small packets.</p><p>The MTU will also differ depending on what network path you take. You can use a protocol like <a href=https://tools.ietf.org/html/rfc1191>Path MTU Discovery</a> to figure out the largest packet size you can send.</p><h2 id=media-101>Media 101
<a class=anchor href=#media-101>#</a></h2><h3 id=codec>Codec
<a class=anchor href=#codec>#</a></h3><h3 id=frame-types>Frame Types
<a class=anchor href=#frame-types>#</a></h3><h2 id=rtp>RTP
<a class=anchor href=#rtp>#</a></h2><h3 id=packet-format>Packet Format
<a class=anchor href=#packet-format>#</a></h3><p>Every RTP packet has the following structure:</p><pre><code> 0                   1                   2                   3
 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|V=2|P|X|  CC   |M|     PT      |       Sequence Number         |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|                           Timestamp                           |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|           Synchronization Source (SSRC) identifier            |
+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+
|            Contributing Source (CSRC) identifiers             |
|                             ....                              |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|                            Payload                            |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
</code></pre><h4 id=version-v>Version (V)
<a class=anchor href=#version-v>#</a></h4><p><code>Version</code> is always <code>2</code></p><h4 id=padding-p>Padding (P)
<a class=anchor href=#padding-p>#</a></h4><p><code>Padding</code> is a bool that controls if the payload has padding.</p><p>The last byte of the payload contains a count of how many padding bytes were added.</p><h4 id=extension-x>Extension (X)
<a class=anchor href=#extension-x>#</a></h4><p>If set, the RTP header will have extensions. This is described in greater detail below.</p><h4 id=csrc-count-cc>CSRC count (CC)
<a class=anchor href=#csrc-count-cc>#</a></h4><p>The amount of <code>CSRC</code> identifiers that follow after the <code>SSRC</code>, and before the payload.</p><h4 id=marker-m>Marker (M)
<a class=anchor href=#marker-m>#</a></h4><p>The marker bit has no pre-set meaning, and is up to the user.</p><p>In some cases it is set when a user is speaking. It is also commonly used to mark a keyframe.</p><h4 id=payload-type-pt>Payload Type (PT)
<a class=anchor href=#payload-type-pt>#</a></h4><p><code>Payload Type</code> is a unique identifier for what codec is being carried by this packet.</p><p>For WebRTC the <code>Payload Type</code> is dynamic. VP8 in one call may be different then another. The Offerer in the call determines the mapping of <code>Payload Types</code> to codecs in the <code>Session Description</code>.</p><h4 id=sequence-number>Sequence Number
<a class=anchor href=#sequence-number>#</a></h4><p><code>Sequence Number</code> is used for ordering packets in a stream. Every time a packet is sent the <code>Sequence Number</code> is incremented by one.</p><p>RTP is designed to be useful over lossy networks. This gives the receiver a way to detect when packets have been lost.</p><h4 id=timestamp>Timestamp
<a class=anchor href=#timestamp>#</a></h4><p>The sampling instant for this packet. This is not a global clock, but how much time has passed in the media stream.</p><h4 id=synchronization-source-ssrc>Synchronization Source (SSRC)
<a class=anchor href=#synchronization-source-ssrc>#</a></h4><p>A <code>SSRC</code> is the unique identifier for this stream. This allows you to run multiple streams of media over a single stream.</p><h4 id=contributing-source-csrc>Contributing Source (CSRC)
<a class=anchor href=#contributing-source-csrc>#</a></h4><p>A list that communicates what <code>SSRC</code>es contributed to this packet.</p><p>This is commonly used for talking indicators. Lets say server side you combined multiple audio feeds into a single RTP stream. You could then use this field to say &lsquo;Input stream A and C were talking at this moment&rsquo;</p><h4 id=payload>Payload
<a class=anchor href=#payload>#</a></h4><p>The actual payload data. Might end with the count of how many padding bytes were added, if the padding flag is set.</p><h3 id=extensions>Extensions
<a class=anchor href=#extensions>#</a></h3><h3 id=mapping-payload-types-to-codecs>Mapping Payload Types to Codecs
<a class=anchor href=#mapping-payload-types-to-codecs>#</a></h3><h2 id=rtcp>RTCP
<a class=anchor href=#rtcp>#</a></h2><h3 id=packet-format-1>Packet Format
<a class=anchor href=#packet-format-1>#</a></h3><p>Every RTCP packet has the following structure:</p><pre><code> 0                   1                   2                   3
 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|V=2|P|    RC   |       PT      |             length            |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|                            Payload                            |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
</code></pre><h4 id=version-v-1>Version (V)
<a class=anchor href=#version-v-1>#</a></h4><p><code>Version</code> is always <code>2</code></p><h4 id=padding-p-1>Padding (P)
<a class=anchor href=#padding-p-1>#</a></h4><p><code>Padding</code> is a bool that controls if the payload has padding.</p><p>The last byte of the payload contains a count of how many padding bytes
were added.</p><h4 id=reception-report-count-rc>Reception Report Count (RC)
<a class=anchor href=#reception-report-count-rc>#</a></h4><p>The number of reports in this packet. A single RTCP Packet can contain multiple events.</p><h4 id=packet-type-pt>Packet Type (PT)
<a class=anchor href=#packet-type-pt>#</a></h4><p>Unique Identifier for what type of RTCP Packet this is. A WebRTC Agent doesn&rsquo;t need to support all these types, and support between Agents can be different. These are the ones you may commonly see though.</p><ul><li>Full INTRA-frame Request (FIR) - <code>192</code></li><li>Negative ACKnowledgements (NACK) - <code>193</code></li><li>Sender Report - <code>200</code></li><li>Receiver Report - <code>201</code></li><li>Generic RTP Feedback - <code>205</code></li></ul><p>The significance of these packet types will be described in greater detail below.</p><h3 id=full-intra-frame-request>Full INTRA-frame Request
<a class=anchor href=#full-intra-frame-request>#</a></h3><p>This RTCP message notifies the sender that it needs to send a full image. This is for when the encoder is giving you partial frames, but you aren&rsquo;t able to decode them.</p><p>This could happen because you had lots of packet loss, or maybe the decoder crashed.</p><h3 id=negative-acknowledgements>Negative ACKnowledgements
<a class=anchor href=#negative-acknowledgements>#</a></h3><p>A NACK requests that a sender re-transmits a single RTP Packet. This is usually caused when a RTP Packet is lost, but could also happen because it is late.</p><p>NACKs are much more bandwidth efficent then requesting that the whole frame get sent again. Since RTP breaks up packets into very small chunks, you are really just requesting one small missing piece.</p><h3 id=senderreceiver-reports>Sender/Receiver Reports
<a class=anchor href=#senderreceiver-reports>#</a></h3><p>These reports are used to send statistics between agents. This communicates the amount of packets actually received and jitter.</p><p>The reports can be used for diagnostics or basic Congestion Control.</p><h3 id=generic-rtp-feedback>Generic RTP Feedback
<a class=anchor href=#generic-rtp-feedback>#</a></h3><h2 id=how-rtprtcp-solve-problems>How RTP/RTCP solve problems
<a class=anchor href=#how-rtprtcp-solve-problems>#</a></h2><p>RTP and RTCP then work together to solve all the problems caused by networks. These techniques are still constantly changing!</p><h3 id=negative-acknowledgment>Negative Acknowledgment
<a class=anchor href=#negative-acknowledgment>#</a></h3><p>Also known as a NACK. This is one method of dealing with packet loss with RTP.</p><p>A NACK is a RTCP message sent back to a sender to request re-transmission. The receiver crafts a RTCP message with the SSRC and Sequence Number. If the sender does not have this RTP packet available to re-send, it just ignores the message.</p><h3 id=forward-error-correction>Forward Error Correction
<a class=anchor href=#forward-error-correction>#</a></h3><p>Also known as FEC. Another method of dealing with packet loss. FEC is when you send the same data multiple times, without it even being requested. This is done at the RTP level, or even lower with the codec.</p><p>If the packet loss for a call is steady then FEC is a much lower latency solution than NACK. The round trip time of having to request, and then re-transmit the packet can be significant for NACKs.</p><h3 id=adaptive-bitrate-and-bandwidth-estimation>Adaptive bitrate and Bandwidth Estimation
<a class=anchor href=#adaptive-bitrate-and-bandwidth-estimation>#</a></h3><p>A common problem of modern IP networks, both wireless and wired, is unpredictable and unreliable bandwidth. Network conditions are changing dynamically multiple times throughout a session. It is not uncommon to see available bandwidth change drammatically (orders of magnitude) within a second.</p><p>Unpredictability in wired networks can be caused by changing demand for bandwidth across the network, routing changes, limitations of transfer medium (fiber channel vs ethernet vs dsl) and more.</p><p>In addition to issues seen in wired networks, the nature of radio signal transmission itself, interference from multiple sources, distance to cell towers or Wi-Fi access points and physical obstacles (read walls) are some reasons for unpredictable wireless network characteristics.</p><p>WebRTC has several mechanisms to help deliver video/audio signals to the receiver despite changing network conditions.
The main idea is to adjust encoding bitrate based on predicted, current, and future available network bandwidth.
This ensures that video/audio signal of the best possible quality is transmitted and the connection does not get dropped because of network congestion.
Heuristics that model the network behavior and tries to predict it is known as Bandwidth estimation.</p><h4 id=remb>REMB
<a class=anchor href=#remb>#</a></h4><p>A widely supported albeit never fully standardized and now considered deprecated method is called <a href=https://tools.ietf.org/html/draft-alvestrand-rmcat-remb-03>REMB</a> (Receiver Estimated Maximum Bitrate).
REMB is a special RTCP packet the receiver sends to the sender, notifying the sender of available bandwidth. There is no(?) standard method defined to estimate bandwidth associated with REMB, so the actual values are implementation dependent. A good starting point for research into details of REMB is the <a href=https://source.chromium.org/chromium/chromium/src/+/master:third_party/webrtc/modules/rtp_rtcp/source/rtcp_packet/remb.cc>Chrome source code</a>.</p><p>The only useful payload in the packet is the bitrate, measured in bits per second.
Notable ambiguity and a source of confusion is that REMB is defined as the <em>total</em> bitrate, while it is common to see WebRTC libraries use it to constrain video encoding bitrate only.</p><p><figure><img src=/images/05-remb.png></figure><img src=../images/05-remb.png alt=REMB></p><h3 id=congestion-control>Congestion Control
<a class=anchor href=#congestion-control>#</a></h3><p>Experienced WebRTC practitioners <a href=https://gstconf.ubicast.tv/videos/google-transport-wide-congestion-control/>say</a> that REMB&rsquo;s approach leaves scars, angry looks and even laughs from Google engineers.</p><p>Congestion Control is the act of adjusting the media depending on the attributes of the network. If you don&rsquo;t have a lot of bandwidth, you need to send lower quality video.</p><p>Congestion Control improves WebRTC experience by providing a more fine grained control and monitoring of network connection and conditions.</p><h4 id=twcc>TWCC
<a class=anchor href=#twcc>#</a></h4><p>Transport-Wide Congestion Control (TWCC) is an advanced congestion control specification implemented in most browsers.</p><p>TWCC uses a quite simple principle:</p><p><figure><img src=/images/05-twcc-idea.png></figure><img src=../images/05-twcc-idea.png alt=TWCC></p><p>Unlike in REMB, a TWCC receiver doesn&rsquo;t try to estimate it&rsquo;s own incoming bitrate. It just lets the sender know which packets where received and when. Based on these reports, the sender has a very up-to-date idea of what is happening in the network.</p><ul><li>The sender creates an RTP packet with a special TWCC header extension, containing a list of packet sequence numbers.</li><li>The receiver responds with a special RTCP feedback message letting the sender know if and when each packet was received.</li></ul><p>The sender keeps track of sent packets, their sequence numbers, sizes and timestamps.
When the sender receives RTCP messages from the receiver, it compares the send inter-packet delays with receive delays.
If the receive delays increase, it means network congestion is happenning and the sender must act on it.</p><p>In the diagram below, the median interpacket delay increase is +20 msec, a clear indicator of network congestion happening.</p><p><figure><img src=/images/05-twcc.png></figure><img src=../images/05-twcc.png alt=TWCC></p><p>TWCC provides the raw data and an excellent view into real time network conditions:</p><ul><li>Almost instant packet loss statistics, not only the percentage lost, but the exact packets that were lost.</li><li>Accurate send bitrate.</li><li>Accurate receive bitrate.</li><li>A jitter estimate.</li><li>Differences between send and receive packet delays.</li></ul><p>A trivial congestion control algrorithm to estimate the incoming bitrate on the receiver from the sender is to sum up packet sizes received, and divide it by the remote time elapsed.</p><p>More sophisticated congestion control algorithms like <a href=https://tools.ietf.org/html/draft-alvestrand-rmcat-congestion-02>A Google Congestion Control Algorithm for Real-Time Communication</a>, GCC for short, are built on top of the raw TWCC data.
GCC was proposed by Google and implemented in Chrome.
It predicts the current and future network bandwidth by using a <a href=https://en.wikipedia.org/wiki/Kalman_filter>Kalman filter</a>.</p><p>There are several alternatives to GCC, for example <a href=https://tools.ietf.org/html/draft-zhu-rmcat-nada-04>NADA: A Unified Congestion Control Scheme for Real-Time Media</a> and <a href=https://tools.ietf.org/html/draft-johansson-rmcat-scream-cc-05>SCReAM - Self-Clocked Rate Adaptation for Multimedia</a>.</p><p><strong>Q</strong>: How can I tell that TWCC is supported and enabled?</p><p><strong>A</strong>: Look at the SDP offer/answer. If you see the lines below, you have TWCC negotiated on your connection:</p><pre><code>a=extmap:5 http://www.ietf.org/id/draft-holmer-rmcat-transport-wide-cc-extensions
</code></pre><p>and</p><pre><code>a=rtcp-fb:96 transport-cc
</code></pre><h3 id=jitterbuffer>JitterBuffer
<a class=anchor href=#jitterbuffer>#</a></h3></article><footer class=book-footer><div class="flex flex-wrap justify-between"><div class=book-languages tabindex=0 aria-haspopup=true><ul><li class="flex align-center"><img src=/svg/translate.svg class=book-icon alt=Languages>
English</li></ul><ul class=book-languages-list><li class=active><a href=https://webrtcforthecurious.com/ class="flex align-center"><img src=/svg/translate.svg class=book-icon alt=Languages>
English</a></li><li><a href=https://webrtcforthecurious.com/tr/docs/06-media-communication/ class="flex align-center"><img src=/svg/translate.svg class=book-icon alt=Languages>
Turkish</a></li><li><a href=https://webrtcforthecurious.com/fa/ class="flex align-center"><img src=/svg/translate.svg class=book-icon alt=Languages>
Persian</a></li><li><a href=https://webrtcforthecurious.com/zh/docs/06-media-communication/ class="flex align-center"><img src=/svg/translate.svg class=book-icon alt=Languages>
简体中文</a></li></ul></div><div><a class="flex align-center" href=https://github.com/webrtc-for-the-curious/webrtc-for-the-curious/commit/b54da1379c0552e164e8e97b5970cfb1b11abb8f title="Last modified by Sean DuBois | February 27, 2021" target=_blank rel=noopener><img src=/svg/calendar.svg class=book-icon alt=Calendar>
<span>February 27, 2021</span></a></div><div><a class="flex align-center" href=https://github.com/webrtc-for-the-curious/webrtc-for-the-curious/edit/master/content//docs/06-media-communication.md target=_blank rel=noopener><img src=/svg/edit.svg class=book-icon alt=Edit>
<span>Edit this page</span></a></div></div></footer><div class=book-comments></div><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><nav id=TableOfContents><ul><li><a href=#how-does-it-work>How does it work?</a></li><li><a href=#latency-vs-quality>Latency vs Quality</a><ul><li><a href=#real-world-limitations>Real World Limitations</a></li></ul></li><li><a href=#media-101>Media 101</a><ul><li><a href=#codec>Codec</a></li><li><a href=#frame-types>Frame Types</a></li></ul></li><li><a href=#rtp>RTP</a><ul><li><a href=#packet-format>Packet Format</a></li><li><a href=#extensions>Extensions</a></li><li><a href=#mapping-payload-types-to-codecs>Mapping Payload Types to Codecs</a></li></ul></li><li><a href=#rtcp>RTCP</a><ul><li><a href=#packet-format-1>Packet Format</a></li><li><a href=#full-intra-frame-request>Full INTRA-frame Request</a></li><li><a href=#negative-acknowledgements>Negative ACKnowledgements</a></li><li><a href=#senderreceiver-reports>Sender/Receiver Reports</a></li><li><a href=#generic-rtp-feedback>Generic RTP Feedback</a></li></ul></li><li><a href=#how-rtprtcp-solve-problems>How RTP/RTCP solve problems</a><ul><li><a href=#negative-acknowledgment>Negative Acknowledgment</a></li><li><a href=#forward-error-correction>Forward Error Correction</a></li><li><a href=#adaptive-bitrate-and-bandwidth-estimation>Adaptive bitrate and Bandwidth Estimation</a></li><li><a href=#congestion-control>Congestion Control</a></li><li><a href=#jitterbuffer>JitterBuffer</a></li></ul></li></ul></nav></aside></main></body></html>